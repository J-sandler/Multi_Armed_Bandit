# Multi_Armed_Bandit
A study in the comparison of multi armed bandit strategies including a novel machine learning approach
